{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\divya\\anaconda3\\lib\\site-packages (1.3.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_data = pd.read_csv(\"C:/Users/DIVYA/Downloads/Youtube_combined_data.csv\", encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-15 11:18:12,120 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-10-15 11:18:12,122 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-10-15 11:18:12,125 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-10-15 11:18:12,129 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///Adaptive_playlist.db', echo=True)\n",
    "sqlite_connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-15 11:18:12,214 INFO sqlalchemy.engine.base.Engine PRAGMA main.table_info(\"youtube_scraped_data\")\n",
      "2020-10-15 11:18:12,218 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-10-15 11:18:12,223 INFO sqlalchemy.engine.base.Engine PRAGMA temp.table_info(\"youtube_scraped_data\")\n",
      "2020-10-15 11:18:12,225 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-10-15 11:18:12,231 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE youtube_scraped_data (\n",
      "\t\"index\" BIGINT, \n",
      "\t\"URL\" TEXT, \n",
      "\t\"Title\" TEXT, \n",
      "\t\"Description\" TEXT, \n",
      "\t\"Tags\" TEXT, \n",
      "\t\"Category\" TEXT\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-15 11:18:12,232 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-10-15 11:18:12,520 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-15 11:18:12,525 INFO sqlalchemy.engine.base.Engine CREATE INDEX ix_youtube_scraped_data_index ON youtube_scraped_data (\"index\")\n",
      "2020-10-15 11:18:12,531 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-10-15 11:18:12,662 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-15 11:18:12,767 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n",
      "2020-10-15 11:18:13,478 INFO sqlalchemy.engine.base.Engine INSERT INTO youtube_scraped_data (\"index\", \"URL\", \"Title\", \"Description\", \"Tags\", \"Category\") VALUES (?, ?, ?, ?, ?, ?)\n",
      "2020-10-15 11:18:13,479 INFO sqlalchemy.engine.base.Engine ((0, 'https://www.youtube.com/watch?v=NCkTaD8tjtU', 'Husqvarna Svartpilen 250 & Vitpilen 250 review -The sweet duo from Sweden |First Ride| Autocar India', 'The Husqvarna Svartpilen 250 and Husqvarna Vitpilen 250 are finally here. Rishaad Mody introduces you to brand Husqvarna and gets astride the uber st ... (786 characters truncated) ... parison tests â\\x96ºhttp://bit.ly/ACI-Comparison\\n\\nNew bike reviews â\\x96ºhttp://bit.ly/ACI-BikeReviews\\n\\nFeatures â\\x96ºhttp://bit.ly/ACI-Features', \"['Autocar', 'India', 'Autocar India', 'Car Reviews', 'Video Reviews', 'Test Drives', 'Husqvarna Svartpilen 250', 'Vitpilen 250', 'husqvarna vitpilen  ... (208 characters truncated) ... cles india', 'vitpilen 250 2020', 'husqvarna vitpilen', 'husqvarna', 'vitpilen 250 review', 'vitpilen 250 top speed', 'vitpilen 401', 'vtipilen 250']\", 'Automobiles'), (1, 'https://www.youtube.com/watch?v=J5BMlYd9YzA', '2020 Mahindra Thar â\\x80\\x93 Happy Independence Day! | First Look | Autocar India', 'The wait is over! The all-new, second-gen Mahindra Thar has been revealed in full ahead of its market launch on October 2, 2020. Renuka Kirpalani bri ... (1407 characters truncated) ... parison tests â\\x96ºhttp://bit.ly/ACI-Comparison\\n\\nNew bike reviews â\\x96ºhttp://bit.ly/ACI-BikeReviews\\n\\nFeatures â\\x96ºhttp://bit.ly/ACI-Features', \"['autocar', 'autocar india', 'mahindra thar', 'thar', 'thar 2020', 'mahindra thar 2020', 'mahindra thar 2020 features', 'mahindra thar 2020 model', ' ... (225 characters truncated) ... ar launch', 'mahindra thar price', 'thar new', 'thar modified', 'independence day', 'thar car', 'thar jeep', 'mahindra', 'thar india', 'thar review']\", 'Automobiles'), (2, 'https://www.youtube.com/watch?v=gY_Qf_Z-PzU', 'Ford Freestyle Flair, Triumph Street Triple R, Hyundai Ioniq and more | Quick News | Autocar India', \"In this episode of Autocar India Quick News, we bring you all the launches and price updates of the week starting from the Tata Altroz, Ford Endeavou ... (1753 characters truncated) ... n\\nNew bike reviews â\\x96ºhttp://bit.ly/ACI-BikeReviews\\n\\nFeatures â\\x96ºhttp://bit.ly/ACI-Features\\n\\n#HyundaiIoniq #FordFreestyleFlair #TataAltroz\", \"['Autocar', 'India', 'Autocar India', 'Car Reviews', 'Video Reviews', 'Test Drives', 'Ford Freestyle Flair', 'Triumph Street Triple R', 'Hyundai Ioni ... (223 characters truncated) ... troz price', 'honda jazz bs6 2020', 'new honda jazz bs6 diesel', 'hyundai ioniq review', 'ford freestyle flair review', 'kawasaki versys 650 review']\", 'Automobiles'), (3, 'https://www.youtube.com/watch?v=LylE-gb-Blg', 'Track attack with the Renault Duster 1.3L Turbo Petrol | Special Feature | Autocar India', \"After being impressed by its flat-out acceleration, Aditya Patel takes the Renault Duster 1.3L Turbo Petrol on a lap of the MMRT to see if the SUV's  ... (751 characters truncated) ... parison tests â\\x96ºhttp://bit.ly/ACI-Comparison\\n\\nNew bike reviews â\\x96ºhttp://bit.ly/ACI-BikeReviews\\n\\nFeatures â\\x96ºhttp://bit.ly/ACI-Features\", \"['autocar india', 'autocar', 'renault duster 1.3l turbo petrol', 'renault duster 1.3 turbo petrol', 'renault duster 1.3 turbo', 'renault duster turbo ... (219 characters truncated) ... enault duster', 'renault duster 1.3 turbo petrol price', 'renault duster 1.3 turbo petrol india', 'new renault duster', 'renault duster petrol 2020']\", 'Automobiles'), (4, 'https://www.youtube.com/watch?v=siO2zLA2sl4', '2020 Nissan Kicks Turbo - Does the 156hp engine deliver that kick? | First Drive | Autocar India', 'With its 156hp, 1.3-litre turbo-petrol engine, the 2020 Nissan Kicks is the most powerful petrol mid-size SUV in India. Is it fun to drive? Shapur Ko ... (733 characters truncated) ... parison tests â\\x96ºhttp://bit.ly/ACI-Comparison\\n\\nNew bike reviews â\\x96ºhttp://bit.ly/ACI-BikeReviews\\n\\nFeatures â\\x96ºhttp://bit.ly/ACI-Features', \"['Autocar', 'India', 'Autocar India', 'Car Reviews', 'Video Reviews', 'Test Drives', 'nissan kicks turbo review', 'nissan kicks 2020', 'nissan kicks' ... (214 characters truncated) ... cks india', 'car review india', 'nissan suv', 'nissan kicks 156 bhp', 'nissan kicks 2020 review', 'renault duster', 'indian car review', 'kicks car']\", 'Automobiles'), (5, 'https://www.youtube.com/watch?v=eKq8Dyz_Mm8', 'Flat Out with the Renault Duster 1.3L Turbo Petrol | Special Feature | Autocar India', 'One-track mind: GT racer Aditya Patel encounters the new Renault Duster 1.3 Turbo Petrol on a race track. What happens next?\\n\\n#RenaultDUSTER #Turbo ... (677 characters truncated) ... parison tests â\\x96ºhttp://bit.ly/ACI-Comparison\\n\\nNew bike reviews â\\x96ºhttp://bit.ly/ACI-BikeReviews\\n\\nFeatures â\\x96ºhttp://bit.ly/ACI-Features', \"['autocar india', 'autocar', 'renault duster 1.3l turbo petrol', 'renault duster 1.3 turbo petrol', 'renault duster 1.3 turbo', 'renault duster turbo ... (219 characters truncated) ... enault duster', 'renault duster 1.3 turbo petrol price', 'renault duster 1.3 turbo petrol india', 'new renault duster', 'renault duster petrol 2020']\", 'Automobiles'), (6, 'https://www.youtube.com/watch?v=_0k070RDUkU', 'Brute force: Mercedes-AMG C 63 CoupÃ© and GT 63 S 4-Door CoupÃ© | Feature | Autocar India', 'Would it be the 2 door, 476hp, Rs 1.33 crore Mercedes-AMG C 63 CoupÃ©  for you? Or is the 4 door, 639hp, Rs 2.42 crore Mercedes-AMG GT 63 S 4-Door Co ... (752 characters truncated) ... parison tests â\\x96ºhttp://bit.ly/ACI-Comparison\\n\\nNew bike reviews â\\x96ºhttp://bit.ly/ACI-BikeReviews\\n\\nFeatures â\\x96ºhttp://bit.ly/ACI-Features', \"['autocar india', 'autocar', 'brute force', 'mercedes amg c 63 coupÃ©', 'mercedes amg c 63 coupe', 'mercedes amg c63 coupe', 'GT 63 S 4 Door CoupÃ©', ... (237 characters truncated) ... eleration', 'mercedes c63 amg pov', 'mercedes gt63s', 'mercedes gt63s amg india', 'bmw amg gt', 'bmw amg series', 'bmw sports car', 'bmw racing car']\", 'Automobiles'), (7, 'https://www.youtube.com/watch?v=OFXOLZ92Qbk', '2020 Toyota Innova Crysta automatic - BS6 2.4 diesel gets 6-speed AT  | First Drive | Autocar India', \"The Toyota Innova Crysta has been upgraded for BS6 emission norms. In the transformation, the old 2.8-litre diesel-automatic combo has been replaced  ... (869 characters truncated) ... parison tests â\\x96ºhttp://bit.ly/ACI-Comparison\\n\\nNew bike reviews â\\x96ºhttp://bit.ly/ACI-BikeReviews\\n\\nFeatures â\\x96ºhttp://bit.ly/ACI-Features\", \"['Autocar', 'India', 'Autocar India', 'Car Reviews', 'Video Reviews', 'toyota innova crysta automatic review', 'toyota', 'car review', 'test drive',  ... (243 characters truncated) ... 0', 'toyota car', 'cars in india', '2020 innova crysta', 'innova top model', 'innova bs6 2.4 automatic', 'toyota innova review', 'innova crysta bs6']\", 'Automobiles')  ... displaying 10 of 45446 total bound parameter sets ...  (45444, 'https://www.youtube.com/watch?v=YrUEQ7s-ftc', 'Galaxy Note 10+ Star Wars Edition Unboxing & First Look + Giveaway | The Best Beastð\\x9f\\x94¥ð\\x9f\\x94¥ð\\x9f\\x94¥', 'Participate here: https://gleam.io/HkaUC/tg-galaxy-note-10-star-wars-edition-giveaway\\nNamaskaar Dosto, is video mein maine aapse baat ki hai Samsung ... (765 characters truncated) ... hnicalguruji.in/\\n\\nAbout : Technical Guruji is a YouTube Channel, where you will find technological videos in Hindi, New Video is Posted Everyday :)', \"['galaxy note 10', 'galaxy note 10+', 'note 10+', 'note 10 plus', 'star wars', 'note 10 star wars', 'samsung', 'samsung galaxy star wars', 'star wars ... (221 characters truncated) ... e 10+ review', 'iphone', 'apple', 'iphone 11', 'iphone 11 pro', 'iphone 11 pro max', 'vs', 'Technicalguruji', 'Technical guruji', 'Gaurav Chaudhary']\", 'Videoblogging'), (45445, 'https://www.youtube.com/watch?v=BdsPYaVEJe8', '#155 Sunday Tech Masala - Best Smartphone Of 2019??? #BoloGurujið\\x9f\\x94¥ð\\x9f\\x94¥ð\\x9f\\x94¥', 'Be a Member: https://www.youtube.com/channel/UCOhHO2ICt0ti9KAh-QHvttQ/join\\nNamaskaar Dosto, yeh ek aur naya video hai Sunday Tech Masala ke ek naye  ... (619 characters truncated) ... hnicalguruji.in/\\n\\nAbout : Technical Guruji is a YouTube Channel, where you will find technological videos in Hindi, New Video is Posted Everyday :)', \"['technical guruji', 'Sunday Masala', 'funny', 'technology', 'tech', 'masala', 'sunday tech masala', 'technicalguruji', 'giveaway', 'surprise', 'yout ... (277 characters truncated) ... o', '64MP', 'Redmi Note 8 Pro', 'iPhone 11', 'iPhone 11 Pro', 'Realme X2 Pro', 'TikTok', 'Tesla Cybertruck', 'Cybertruck', 'Sunday Tech Masala #155']\", 'Videoblogging'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-15 11:18:15,004 INFO sqlalchemy.engine.base.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "sqlite_table = \"youtube_scraped_data\"\n",
    "raw_data.to_sql(sqlite_table, sqlite_connection, if_exists='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Read sqlite query results into a pandas DataFrame\n",
    "con = sqlite3.connect(\"Adaptive_playlist.db\")\n",
    "df = pd.read_sql_query(\"SELECT * from youtube_scraped_data\", con)\n",
    "\n",
    "# Verify that result of SQL query is stored in the dataframe\n",
    "print(df.head())\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"Adaptive_playlist.db\")\n",
    "data = pd.read_sql_query(\"SELECT Title,Description,Tags,Category from youtube_scraped_data\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "#from wordcloud import WordCloud\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "#import mplcursors\n",
    "\n",
    "# from os import path\n",
    "# from PIL import Image\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To replace nan values with dot\n",
    "for i in data.columns:\n",
    "    data[i] = data[i].replace(np.nan, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(df1):\n",
    "    \"Extract relevant text from DataFrame using a regex\"\n",
    "    # Regex pattern for only alphanumeric, hyphenated text with 3 or more chars\n",
    "    pattern = re.compile(r\"[A-Za-z\\-]{3,50}\")\n",
    "    df1['Title'] = data['Title'].str.findall(pattern).str.join(' ')\n",
    "    df1['Description'] = data['Description'].str.findall(pattern).str.join(' ')\n",
    "    df1['Tags'] = data['Tags'].str.findall(pattern).str.join(' ')\n",
    "    #Removing numbers\n",
    "#     df1['Title'] = df1['Title'].str.replace('\\d+', '')\n",
    "#     df1['Description'] = df1['Description'].str.replace('\\d+', '')\n",
    "#     df1['Tags'] = df1['Tags'].str.replace('\\d+', '')\n",
    "#     df1['Description'] = df1['Description'].str.replace('http\\S+|www.\\S+|html\\S+|-\\S+|com\\S+|youtube\\S+|https\\S+','', case=False)\n",
    "#     df1['Tags'] = df1['Tags'].str.replace('http\\S+|www.\\S+|html\\S+|-\\S+|com\\S+|youtube\\S+|https\\S+','', case=False)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = cleaner(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df= pd.DataFrame(columns=[\"Title_token\", \"Desc_token\", \"Tags_token\", \"Category\"])\n",
    "nlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_token_allowed(token):\n",
    "    '''\n",
    "        Only allow valid tokens which are not stop words\n",
    "        and punctuation symbols.\n",
    "    '''\n",
    "    if (not token or not token.string.strip() or\n",
    "        token.is_stop or token.is_punct):\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def preprocess_token(token):\n",
    "    # Reduce token to its lowercase lemma form\n",
    "    token = token.lemma_.strip().lower()\n",
    "#     token = token.replace('http\\S+|www.\\S+|html\\S+|-\\S+|com\\S+|youtube\\S+|https\\S+','')#, case=False)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(main_df,nlp_df):\n",
    "#     nlp_df= pd.DataFrame(columns=[\"Title_token\", \"Desc_token\", \"Tags\", \"Category\"])\n",
    "    for i in main_df.index:\n",
    "        a = {}\n",
    "        row = main_df.iloc[i,].tolist()\n",
    "#         print(row)\n",
    "        for j in range(len(row)):\n",
    "            doc_item = nlp(row[j])\n",
    "            tokens = [preprocess_token(token) for token in doc_item if is_token_allowed(token)]\n",
    "#             tokens_nostop = [token for token in tokens if token not in spacy_stopwords]   #No neeeddddd\n",
    "            a.update({nlp_df.columns[j]:str(tokens).strip(\"[]\")})\n",
    "#             break\n",
    "#             print(tokens)\n",
    "#         print(a)\n",
    "        nlp_df = nlp_df.append(a, ignore_index=True)\n",
    "#         break\n",
    "    return nlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df =get_tokens(df_preproc,nlp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_token</th>\n",
       "      <th>Desc_token</th>\n",
       "      <th>Tags_token</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'husqvarna', 'svartpilen', 'vitpilen', 'review...</td>\n",
       "      <td>'husqvarna', 'svartpilen', 'husqvarna', 'vitpi...</td>\n",
       "      <td>'autocar', 'india', 'autocar', 'india', 'car',...</td>\n",
       "      <td>'automobile'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'mahindra', 'thar', 'happy', 'independence', '...</td>\n",
       "      <td>'wait', 'new', 'second', 'gen', 'mahindra', 't...</td>\n",
       "      <td>'autocar', 'autocar', 'india', 'mahindra', 'th...</td>\n",
       "      <td>'automobile'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'ford', 'freestyle', 'flair', 'triumph', 'stre...</td>\n",
       "      <td>'episode', 'autocar', 'india', 'quick', 'news'...</td>\n",
       "      <td>'autocar', 'india', 'autocar', 'india', 'car',...</td>\n",
       "      <td>'automobile'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'track', 'attack', 'renault', 'duster', 'turbo...</td>\n",
       "      <td>'impress', 'flat', 'acceleration', 'aditya', '...</td>\n",
       "      <td>'autocar', 'india', 'autocar', 'renault', 'dus...</td>\n",
       "      <td>'automobile'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'nissan', 'kicks', 'turbo', 'engine', 'deliver...</td>\n",
       "      <td>'-litre', 'turbo', 'petrol', 'engine', 'nissan...</td>\n",
       "      <td>'autocar', 'india', 'autocar', 'india', 'car',...</td>\n",
       "      <td>'automobile'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Title_token  \\\n",
       "0  'husqvarna', 'svartpilen', 'vitpilen', 'review...   \n",
       "1  'mahindra', 'thar', 'happy', 'independence', '...   \n",
       "2  'ford', 'freestyle', 'flair', 'triumph', 'stre...   \n",
       "3  'track', 'attack', 'renault', 'duster', 'turbo...   \n",
       "4  'nissan', 'kicks', 'turbo', 'engine', 'deliver...   \n",
       "\n",
       "                                          Desc_token  \\\n",
       "0  'husqvarna', 'svartpilen', 'husqvarna', 'vitpi...   \n",
       "1  'wait', 'new', 'second', 'gen', 'mahindra', 't...   \n",
       "2  'episode', 'autocar', 'india', 'quick', 'news'...   \n",
       "3  'impress', 'flat', 'acceleration', 'aditya', '...   \n",
       "4  '-litre', 'turbo', 'petrol', 'engine', 'nissan...   \n",
       "\n",
       "                                          Tags_token      Category  \n",
       "0  'autocar', 'india', 'autocar', 'india', 'car',...  'automobile'  \n",
       "1  'autocar', 'autocar', 'india', 'mahindra', 'th...  'automobile'  \n",
       "2  'autocar', 'india', 'autocar', 'india', 'car',...  'automobile'  \n",
       "3  'autocar', 'india', 'autocar', 'renault', 'dus...  'automobile'  \n",
       "4  'autocar', 'india', 'autocar', 'india', 'car',...  'automobile'  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing numbers - Added to cleaner() func\n",
    "nlp_df['Title_token'] = nlp_df['Title_token'].str.replace('\\d+', '')\n",
    "nlp_df['Desc_token'] = nlp_df['Desc_token'].str.replace('\\d+', '')\n",
    "nlp_df['Tags_token'] = nlp_df['Tags_token'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing links(http,www,com,youtube etc) - Added to cleaner() func\n",
    "nlp_df['Desc_token'] = nlp_df['Desc_token'].str.replace('http\\S+|www.\\S+|html\\S+|-\\S+|com\\S+|youtube\\S+|https\\S+','', case=False)\n",
    "nlp_df['Tags_token'] = nlp_df['Tags_token'].str.replace('http\\S+|www.\\S+|html\\S+|-\\S+|com\\S+|youtube\\S+|https\\S+','', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"'automobile'\", \"'music'\", \"'entertainment'\", \"'education'\",\n",
       "       \"'film_and_animation'\", \"'food'\", \"'game'\", \"'fashion'\",\n",
       "       \"'news_politic'\", \"'pets_animal'\", \"'religion'\",\n",
       "       \"'science_technology'\", \"'sport'\", \"'travel_events'\",\n",
       "       \"'videoblogging'\"], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = nlp_df.Category.unique()\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(text, cat, main_counts):\n",
    "    freq = pd.Series(' '.join(text).split())\n",
    "    freq=freq.str.cat(sep=\" \")\n",
    "    docs = nlp(freq)\n",
    "    tokens = [preprocess_token(token) for token in docs if is_token_allowed(token)]    \n",
    "    word_counts = Counter(tokens)\n",
    "\n",
    "    counts_df = pd.DataFrame.from_dict(word_counts, orient=\"index\").reset_index()\n",
    "    counts_df = counts_df.rename(columns={\"index\":\"Word\",0:\"Count\"}).sort_values(by=\"Count\", ascending=False)\n",
    "    counts_df[\"Category\"] = cat\n",
    "\n",
    "    main_counts = main_counts.merge(counts_df, on=\"Word\", how=\"outer\")\n",
    "    main_counts.fillna(0, inplace=True)\n",
    "    main_counts[\"Count\"] = main_counts['Count_x'] + main_counts['Count_y']\n",
    "    main_counts[\"Category\"] = cat\n",
    "    main_counts.drop([\"Count_x\", \"Count_y\", \"Category_x\", \"Category_y\"], axis=1, inplace=True)\n",
    "    return main_counts\n",
    "\n",
    "#     top5 = word_counts.most_common(5)\n",
    "#     return counts_df.iloc[:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_freq = pd.DataFrame(columns=[\"Category\",\"Word\", \"Count\"])\n",
    "for category in categories:\n",
    "    midman_df = pd.DataFrame(columns=[\"Category\",\"Word\", \"Count\"])\n",
    "    df_cat = nlp_df[nlp_df.Category==category] \n",
    "#     freq = pd.Series(' '.join(df_cat['Title_token']).split()).value_counts()[:5]\n",
    "#     print(freq)\n",
    "    title_freq = title_freq.append(word_counter(df_cat.Title_token, category,midman_df), ignore_index=True)\n",
    "#     input(\"Enter any key to continue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_freq.Category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_freq.to_csv(\"C:\\\\Users\\\\Divya\\\\Documents\\\\Title_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-06 15:30:12,734 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-10-06 15:30:12,985 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-10-06 15:30:13,022 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2020-10-06 15:30:13,025 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-10-06 15:30:13,337 INFO sqlalchemy.engine.base.Engine PRAGMA main.table_info(\"Title_counts\")\n",
      "2020-10-06 15:30:13,341 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-10-06 15:30:13,434 INFO sqlalchemy.engine.base.Engine PRAGMA temp.table_info(\"Title_counts\")\n",
      "2020-10-06 15:30:13,439 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-10-06 15:30:13,568 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE \"Title_counts\" (\n",
      "\t\"index\" BIGINT, \n",
      "\t\"Category\" TEXT, \n",
      "\t\"Word\" TEXT, \n",
      "\t\"Count\" BIGINT\n",
      ")\n",
      "\n",
      "\n",
      "2020-10-06 15:30:13,569 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-10-06 15:30:13,802 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-06 15:30:13,805 INFO sqlalchemy.engine.base.Engine CREATE INDEX \"ix_Title_counts_index\" ON \"Title_counts\" (\"index\")\n",
      "2020-10-06 15:30:13,805 INFO sqlalchemy.engine.base.Engine ()\n",
      "2020-10-06 15:30:13,956 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-06 15:30:14,044 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n",
      "2020-10-06 15:30:26,891 INFO sqlalchemy.engine.base.Engine INSERT INTO \"Title_counts\" (\"index\", \"Category\", \"Word\", \"Count\") VALUES (?, ?, ?, ?)\n",
      "2020-10-06 15:30:26,917 INFO sqlalchemy.engine.base.Engine ((0, \"'automobile'\", 'powerdrift', 1610), (1, \"'automobile'\", 'india', 809), (2, \"'automobile'\", 'autocar', 650), (3, \"'automobile'\", 'review', 300), (4, \"'automobile'\", 'auto', 236), (5, \"'automobile'\", 'look', 175), (6, \"'automobile'\", 'drive', 172), (7, \"'automobile'\", 'expo', 161)  ... displaying 10 of 47092 total bound parameter sets ...  (47090, \"'videoblogging'\", 'ketan', 1), (47091, \"'videoblogging'\", 'paysa', 1))\n",
      "2020-10-06 15:30:27,349 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2020-10-06 15:30:27,722 INFO sqlalchemy.engine.base.Engine SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\n",
      "2020-10-06 15:30:27,727 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine('sqlite:///Adaptive_playlist.db', echo=True)\n",
    "sqlite_connection = engine.connect()\n",
    "sqlite_table = \"Title_counts\"\n",
    "title_freq.to_sql(sqlite_table, sqlite_connection, if_exists='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index      Category        Word  Count\n",
      "0      0  'automobile'  powerdrift   1610\n",
      "1      1  'automobile'       india    809\n",
      "2      2  'automobile'     autocar    650\n",
      "3      3  'automobile'      review    300\n",
      "4      4  'automobile'        auto    236\n"
     ]
    }
   ],
   "source": [
    "# Read sqlite query results into a pandas DataFrame\n",
    "con = sqlite3.connect(\"Adaptive_playlist.db\")\n",
    "title_data = pd.read_sql_query(\"SELECT * from Title_counts\", con)\n",
    "\n",
    "# Verify that result of SQL query is stored in the dataframe\n",
    "print(title_data.head())\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_freq= pd.DataFrame(columns=[\"Category\",\"Word\", \"Count\"])\n",
    "for category in categories:\n",
    "    midman_df = pd.DataFrame(columns=[\"Category\",\"Word\", \"Count\"])\n",
    "    df_cat = nlp_df[nlp_df.Category==category]\n",
    "    for i in range(0,df_cat.shape[0],200):\n",
    "        if (i+200)<df_cat.shape[0]:l=i+200\n",
    "        else: l = df_cat.shape[0]+1            \n",
    "        midman_df = word_counter(df_cat.Desc_token[i:l], category, midman_df)\n",
    "#         break\n",
    "    midman_df.sort_values(by='Count', ascending=False, inplace=True)\n",
    "#     plot_unigram(midman_df[:20], category)\n",
    "    desc_freq = desc_freq.append(midman_df, ignore_index=True)\n",
    "#     desc_freq.update({category: word_counter(df_cat.Desc_token)})\n",
    "#     input(\"Enter any key to continue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(desc_freq.Category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ad5f273e8248>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\DIVYA\\\\Documents\\\\Desc_counts.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "desc = pd.read_csv(\"C:\\\\Users\\\\DIVYA\\\\Documents\\\\Desc_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///Adaptive_playlist.db', echo=True)\n",
    "sqlite_connection = engine.connect()\n",
    "sqlite_table = \"Desc_counts\"\n",
    "desc_freq.to_sql(sqlite_table, sqlite_connection, if_exists='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sqlite query results into a pandas DataFrame\n",
    "con = sqlite3.connect(\"Adaptive_playlist.db\")\n",
    "desc_data = pd.read_sql_query(\"SELECT * from Desc_counts\", con)\n",
    "\n",
    "# Verify that result of SQL query is stored in the dataframe\n",
    "print(desc_data.head())\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_freq=pd.DataFrame(columns=[\"Category\",\"Word\", \"Count\"])\n",
    "\n",
    "for category in categories:\n",
    "    midman_df = pd.DataFrame(columns=[\"Category\",\"Word\", \"Count\"])\n",
    "    df_cat = nlp_df[nlp_df.Category==category] \n",
    "    \n",
    "    for i in range(0,df_cat.shape[0],200):\n",
    "        if (i+200)<df_cat.shape[0]:l=i+200\n",
    "        else: l = df_cat.shape[0]+1            \n",
    "        midman_df = word_counter(df_cat.Tags_token[i:l], category, midman_df)\n",
    "#         break\n",
    "    midman_df.sort_values(by='Count', ascending=False, inplace=True)\n",
    "#     plot_unigram(midman_df[:20], category)\n",
    "    tags_freq = tags_freq.append(midman_df, ignore_index=True)\n",
    "\n",
    "#     tags_freq = tags_freq.append(word_counter(df_cat.Tags_token, category), ignore_index=True)\n",
    "#     tags_freq.update({category: word_counter(df_cat.Tags_token)})\n",
    "#     input(\"Enter any key to continue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tags_freq.Category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_freq.to_csv(\"C:\\\\Users\\\\DIVYA\\\\Documents\\\\Tags_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///Adaptive_playlist.db', echo=True)\n",
    "sqlite_connection = engine.connect()\n",
    "sqlite_table = \"Tags_counts\"\n",
    "tags_freq.to_sql(sqlite_table, sqlite_connection, if_exists='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sqlite query results into a pandas DataFrame\n",
    "con = sqlite3.connect(\"Adaptive_playlist.db\")\n",
    "tags_data = pd.read_sql_query(\"SELECT * from Tags_counts\", con)\n",
    "\n",
    "# Verify that result of SQL query is stored in the dataframe\n",
    "print(tags_data.head())\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_df.to_csv(\"C:\\\\Users\\\\DIVYA\\\\Documents\\\\Tokenised_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
